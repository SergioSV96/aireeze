{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load numpy arrays for training and testing data\n",
    "train_X, train_Y = np.load('data/processed/train_X.npy'), np.load('data/processed/train_Y.npy')\n",
    "test_X, test_Y = np.load('data/processed/test_X.npy'), np.load('data/processed/test_Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch for keras LSTM regression model with hyperparameters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, InputLayer\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "def create_model(dropout_rate=0.0, LSTM_1_neurons=0, LSTM_2_neurons=0, loss='mae', optimizer='adam', batch_size=32, epochs=100):\n",
    "    ''' Define the model architecture to be used (1 LSTM layer with dropout, 1 LSTM layer with dropout, 1 output dense layer) '''\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(LSTM(LSTM_1_neurons, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(LSTM_2_neurons, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(train_Y.shape[2], activation='linear'))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Perform gridsearch for hyperparameters\n",
    "model = KerasRegressor(build_fn=create_model, verbose=2)\n",
    "param_grid = {\n",
    "    'dropout_rate': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'LSTM_1_neurons': [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'LSTM_2_neurons': [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'loss': ['mae', 'mse'],\n",
    "    'batch_size': [32, 64, 128, 256, 512],\n",
    "    'callbacks': [EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001, restore_best_weights=True)]\n",
    "}\n",
    "\n",
    "# Join train and test data for cross-validation\n",
    "X = np.concatenate((train_X, test_X), axis=0)\n",
    "Y = np.concatenate((train_Y, test_Y), axis=0)\n",
    "\n",
    "# Gridsearch for best model but always use the same split for training and testing (i.e. use the same train_X, train_Y, test_X, test_Y)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=PredefinedSplit(test_fold=0), n_jobs=-1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
